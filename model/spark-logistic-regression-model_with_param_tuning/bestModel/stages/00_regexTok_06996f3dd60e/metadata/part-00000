{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1572687027518,"sparkVersion":"2.3.4","uid":"regexTok_06996f3dd60e","paramMap":{"pattern":"\\W+","outputCol":"tokens","toLowercase":true,"gaps":true,"inputCol":"text","minTokenLength":1}}
